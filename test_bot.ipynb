{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de0b6e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from team_code.generate import setup_model_and_tokenizer, generate_text, get_ppl\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import telebot\n",
    "from telebot import types\n",
    "import math\n",
    "import os\n",
    "import uuid\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c02b28c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.0.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.0.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.20s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = setup_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be3e10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = telebot.TeleBot(config.token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce40cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(dir_name):\n",
    "    isExist = os.path.exists(dir_name)\n",
    "    if not isExist:\n",
    "        os.mkdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54bbc7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dir('audio')\n",
    "make_dir('ready')\n",
    "make_dir('voice')\n",
    "make_dir('photo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a0a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_query_list = []\n",
    "history_list = (\"\", \"\")\n",
    "\n",
    "\n",
    "@bot.message_handler(commands=['start'])\n",
    "def send_welcome(message):\n",
    "\n",
    "    global history_list\n",
    "    history_list = (\"\", \"\")\n",
    "#     hideBoard = types.ReplyKeyboardRemove()\n",
    "    msg = bot.send_message(message.chat.id, text ='Здравствуй, {0.first_name}! Я мультимодальный диалоговый ассистент NSU AI, чем могу помочь?'.format(message.from_user))\n",
    "\n",
    "\n",
    "        \n",
    "@bot.message_handler(content_types=['text'])\n",
    "def handle_text(message):\n",
    "    markup=types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
    "    global history_list\n",
    "\n",
    "    try:\n",
    "        \n",
    "        if message.text ==\"Контекст очищен\" or message.text == \"Generating answer...\":\n",
    "            return\n",
    "        if message.text == 'Очистить контекст':\n",
    "            history_list = (\"\",\"\")\n",
    "            bot.send_message(message.chat.id, text=\"Контекст очищен\")\n",
    "        else:\n",
    "            cur_query_list = []\n",
    "\n",
    "            msg = bot.send_message(message.chat.id, text=\"Generating answer...\")\n",
    "            bot.last_message_sent = msg.chat.id, msg.message_id\n",
    "\n",
    "            cur_query_list.append({'type': 'text', 'content': message.text})\n",
    "            btn1 = types.KeyboardButton(\"Очистить контекст\")\n",
    "\n",
    "            markup.add(btn1)\n",
    "            answer, new_history_list = generate_text(model, tokenizer, cur_query_list=cur_query_list, history_list=history_list)\n",
    "            history_list = new_history_list\n",
    "            bot.delete_message(*bot.last_message_sent)\n",
    "            bot.send_message(message.chat.id, text=answer, reply_markup=markup)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    except Exception:\n",
    "        bot.send_message(message.chat.id, text=\"Попробуйте написать текст запроса снова\", reply_markup=markup)\n",
    "\n",
    "\n",
    "    \n",
    "@bot.message_handler(content_types=['photo'])\n",
    "def handle_image(message):\n",
    "    markup=types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
    "            \n",
    "    btn1 = types.KeyboardButton(\"Очистить контекст\")\n",
    "\n",
    "    markup.add(btn1)\n",
    "    cur_query_list = []\n",
    "\n",
    "\n",
    "    try:\n",
    "        msg = bot.send_message(message.chat.id, text=\"Generating answer...\")\n",
    "        if message.caption is not None:\n",
    "            cur_query_list.append({'type': 'text', 'content': message.caption})\n",
    "        else:\n",
    "            cur_query_list.append({'type': 'text', 'content': 'Describe what you see in this picture?'})\n",
    "        bot.last_message_sent = msg.chat.id, msg.message_id\n",
    "        filename = str(uuid.uuid4())\n",
    "        file_name_full=\"./photo/\"+filename +'.jpg'\n",
    "        fileID = message.photo[-1].file_id\n",
    "        file_info = bot.get_file(fileID)\n",
    "        photo = bot.download_file(file_info.file_path)\n",
    "        \n",
    "        with open(file_name_full, 'wb') as new_file:\n",
    "            new_file.write(photo)\n",
    "        cur_query_list.append({'type': 'image', 'content': file_name_full})\n",
    "\n",
    "        global history_list\n",
    "        answer, new_history_list = generate_text(model, tokenizer, cur_query_list=cur_query_list, history_list=history_list)\n",
    "        history_list = new_history_list\n",
    "        bot.delete_message(*bot.last_message_sent)\n",
    "\n",
    "        bot.send_message(message.chat.id, text=answer, reply_markup=markup)\n",
    "\n",
    "       \n",
    "        \n",
    "    except Exception:\n",
    "        \n",
    "        bot.send_message(message.chat.id, text=\"Возникла проблема с вашим фото, попробуйте ещё раз\", reply_markup=markup)\n",
    "\n",
    "        \n",
    "        \n",
    "@bot.message_handler(content_types=['audio', 'document'])\n",
    "def handle_audio(message):\n",
    "    markup=types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
    "        \n",
    "    btn1 = types.KeyboardButton(\"Очистить контекст\")\n",
    "\n",
    "    markup.add(btn1)    \n",
    "\n",
    "    try:\n",
    "        msg = bot.send_message(message.chat.id, text=\"Generating answer...\")\n",
    "        bot.last_message_sent = msg.chat.id, msg.message_id\n",
    "        cur_query_list = []\n",
    "        if message.caption is not None:\n",
    "            cur_query_list.append({'type': 'text', 'content': message.caption})\n",
    "        else:\n",
    "            cur_query_list.append({'type': 'text', 'content': 'Describe what you hear in this audio?'})\n",
    "        filename = str(uuid.uuid4())\n",
    "        file_name_full=\"./audio/\"+filename\n",
    "        file_name_full_converted=\"./ready/\"+filename+\".wav\"\n",
    "        if message.content_type == 'audio':\n",
    "            file_info = bot.get_file(message.audio.file_id)\n",
    "        else:\n",
    "            file_info = bot.get_file(message.document.file_id)\n",
    "\n",
    "        downloaded_file = bot.download_file(file_info.file_path)\n",
    "        with open(file_name_full, 'wb') as new_file:\n",
    "            new_file.write(downloaded_file)\n",
    "        os.system(\"ffmpeg -hide_banner -loglevel error -i \"+file_name_full+\"  \"+file_name_full_converted)\n",
    "        cur_query_list.append({'type': 'audio', 'content': file_name_full_converted})\n",
    "        global history_list\n",
    "        answer, new_history_list = generate_text(model, tokenizer, cur_query_list=cur_query_list, history_list=history_list)\n",
    "        history_list = new_history_list\n",
    "        bot.delete_message(*bot.last_message_sent)\n",
    "        bot.send_message(message.chat.id, text=answer, reply_markup=markup)\n",
    "    except Exception:\n",
    "        bot.send_message(message.chat.id, text=\"Возникла проблема с вашим файлом, убедитесь, что это аудио\", reply_markup=markup)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "@bot.message_handler(content_types=['voice'])\n",
    "def handle_voice(message):\n",
    "    markup=types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
    "        \n",
    "    btn1 = types.KeyboardButton(\"Очистить контекст\")\n",
    "\n",
    "    markup.add(btn1)\n",
    "\n",
    "    try:\n",
    "        msg = bot.send_message(message.chat.id, text=\"Generating answer...\")\n",
    "        bot.last_message_sent = msg.chat.id, msg.message_id\n",
    "        cur_query_list = []\n",
    "\n",
    "        filename = str(uuid.uuid4())\n",
    "        file_name_full=\"./voice/\"+filename+\".ogg\"\n",
    "        file_name_full_converted=\"./ready/\"+filename+\".wav\"\n",
    "        file_info = bot.get_file(message.voice.file_id)\n",
    "        downloaded_file = bot.download_file(file_info.file_path)\n",
    "\n",
    "        with open(file_name_full, 'wb') as new_file:\n",
    "            new_file.write(downloaded_file)\n",
    "        os.system(\"ffmpeg -hide_banner -loglevel error -i \"+file_name_full+\"  \"+file_name_full_converted)\n",
    "        \n",
    "        cur_query_list.append({'type': 'text', 'content': 'Describe this voice message?'})\n",
    "        \n",
    "        cur_query_list.append({'type': 'audio', 'content': file_name_full_converted})\n",
    "\n",
    "        global history_list\n",
    "        answer, new_history_list = generate_text(model, tokenizer, cur_query_list=cur_query_list, history_list=history_list)\n",
    "        history_list = new_history_list\n",
    "        bot.delete_message(*bot.last_message_sent)\n",
    "        bot.send_message(message.chat.id, text=answer, reply_markup=markup)\n",
    "    except Exception:\n",
    "        bot.send_message(message.chat.id, text=\"Возникла проблема с вашим голосовым, попробуйте ещё раз\", reply_markup=markup)\n",
    "        \n",
    "\n",
    "    \n",
    "bot.polling(none_stop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "798e8ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text', 'content': \"Do you know where I've been recently?\"},\n",
       " {'type': 'image', 'content': 'photo.jpg'},\n",
       " {'type': 'audio',\n",
       "  'content': './ready/9e8aeb40-d2c9-4871-a851-e0c9bb632432.wav'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36695b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<s>[INST] You are a useful and friendly interlocutor with great erudition and developed intelligence. You can keep up a conversation on various topics and even know how to play complex intellectual games. What kind of animal is this? Please imagine that you have just heard a sound that probably corresponds to the following text description. \"I Love Little Pussy\", alternatively called \"I Love Little Kitty\", is an English language nursery rhyme about a person who is kind to a pet cat. It has a Roud Folk Song Index number of 12824. [/INST]',\n",
       " 'Based on the description you provided, the animal is most likely a cat. The Roud Folk Song Index number you mentioned corresponds to the song \"I Love Little Pussy,\" which is a nursery rhyme about a person who is fond of their cat. This song is a well-known example of a children\\'s game song, which involves the speaker inviting others to play along by repeating the final line, \"Here I am again.\" The language and melody used in the song are typical of nursery rhymes and are designed to be easy for children to learn and perform.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ded6053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text', 'content': 'What is it on the picture?'},\n",
       " {'type': 'image', 'content': '6.jpg'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_query_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a6211",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0096f5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I believe that sound is most likely that of a mangrove robin bird. The mangrove robin is a passerine bird species belonging to the family Petroicidae. They are found primarily in mangrove forests in northern Australia, as well as in the Aru Islands of New Guinea. The bird's distinctive call can sound similar to a rustling of leaves, which is why it may be easy to mistake it for other types of sounds.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_list = (\"\", \"\")\n",
    "cur_query_list = [{\"type\": \"text\", \"content\": \"Hear the sound? Tell me, what it is?\"}, {\"type\": \"audio\", \"content\": \"00002.wav\"}]\n",
    "answer, new_history_list = generate_text(model, tokenizer, cur_query_list=cur_query_list, history_list=history_list)\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
